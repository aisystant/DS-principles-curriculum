# ZP.5 Вероятность и информация — Ячейки по глубинам

> **Принцип:** ZP.5 Вероятность и информация
> **Источник принципа:** [ZP/principles/ZP.5-probability-and-information.md](../../ZP/principles/ZP.5-probability-and-information.md)
> **Шаблон ячейки:** PACK-education EDU.MAP.001

---

## ZP.5 @ Глубина 1 (Remember)

```yaml
cell:
  principle: ZP.5
  principle_name: Вероятность и информация
  depth: 1
  bloom_level: Remember

  can_do:
    - "Могу сказать: «Это произойдёт скорее всего / вряд ли / наверняка» — и выбрать правильную категорию для 5 из 5 примеров"
    - "Могу отличить «точно произойдёт» от «может произойти» от «точно не произойдёт»"
    - "Могу показать на примере: если в мешке 9 красных и 1 синий шарик, красный выпадет «скорее всего»"
    - "Могу назвать: «неизвестность — это нормально, её можно описать»"

  methods:
    primary: [EDU.M.001]  # Scaffolding — ввод через наблюдение и игру
    meta: [EDU.M.006, EDU.M.007]  # Retrieval + Spaced (всегда)
    notes: "На этой глубине — через тактильный опыт с вероятностными объектами (мешок с шарами, кубик, монета). Младенцы с 4.5 месяцев различают пропорции (Xu & Garcia 2008), с 12 месяцев формируют байесовские ожидания. Опираемся на врождённое чувство пропорции. Ключевое: неопределённость — не пугающая, а описываемая."

  prerequisites:
    same_principle: null  # Первая глубина, пререквизитов нет
    cross_principle: []
    cognitive: "Дооперациональный (3+) или любой начинающий"

  assessment:
    type: observation
    criteria: "Правильно ли сортирует события на «точно / скорее всего / вряд ли / точно нет» (≥4 из 5). Использует ли слова неопределённости спонтанно (не говорит «точно», когда не знает)."
    transfer_test: "Показать новую ситуацию (незнакомая игра с кубиками) → «Что выпадет скорее всего? Почему?»"
    retrieval_test: "Через неделю: «Если в коробке 8 яблок и 2 груши, что ты скорее достанешь с закрытыми глазами?»"

  common_errors:
    - "Путает «я хочу, чтобы произошло» с «скорее всего произойдёт»: wishful thinking подменяет оценку вероятности (desirability bias)"
    - "Считает, что «может произойти» = «произойдёт с вероятностью 50%»: бинарное мышление — либо да, либо нет, без градаций"

  domains: [игры с кубиками/монетками, погода (дождь/солнце), природа (семена прорастут/нет)]

  forms:
    preoperational: "«Мешок сюрпризов»: мешок с 9 красными и 1 синим шариком → достаём по одному, угадываем цвет ДО доставания → считаем попадания. 10 мин"
    concrete_operational: "«Сортировщик шансов»: 15 карточек с событиями → разложить на 4 кучки: «точно / скорее да / скорее нет / точно нет». 15 мин"
    formal_operational: "«Словарь неопределённости»: составить список из 10 утверждений → заменить «точно» на правильную оценку уверенности. 20 мин"
    postformal: "Рефлексия: «Назови 3 решения, которые ты принял на этой неделе. Была ли уверенность обоснованной или мнимой?» 25 мин"

  bridge_template: null  # Первая глубина — нет предыдущего витка
```

---

## ZP.5 @ Глубина 2 (Understand)

```yaml
cell:
  principle: ZP.5
  principle_name: Вероятность и информация
  depth: 2
  bloom_level: Understand

  can_do:
    - "Могу объяснить своими словами: «вероятность — это мера того, насколько мы уверены в событии, от 0 (невозможно) до 1 (точно)»"
    - "Могу объяснить, зачем говорить «с вероятностью P» вместо «да/нет»: потому что это точнее и честнее"
    - "Могу привести пример из жизни, где «скорее всего» оказалось неверным, и объяснить почему"
    - "Могу различить: «часто бывает» (частота) и «я думаю, что скорее всего» (степень уверенности) — два смысла вероятности"

  methods:
    primary: [EDU.M.001, EDU.M.002]  # Scaffolding + PBL (начальный)
    meta: [EDU.M.006, EDU.M.007]
    notes: "Ключевой переход: от интуитивной сортировки к пониманию вероятности как ЧИСЛА на шкале 0-1. Использовать контраст: бинарный прогноз («будет дождь / не будет») vs вероятностный («70% вероятность дождя»). Объяснять два смысла вероятности: частотный (Saffran — младенцы считают переходные вероятности) и байесовский (степень уверенности). Младенцы с 8 месяцев извлекают переходные вероятности из потока слогов."

  prerequisites:
    same_principle: "ZP.5@1"
    cross_principle: []
    cognitive: "Конкретно-операциональный (7+) или взрослый без подготовки"

  assessment:
    type: artifact + observation
    criteria: "Расставляет 5 событий на числовой прямой 0-1 (±0.15 от эталона). Объясняет разницу между «часто бывает» и «я уверен» на примере. Правильно интерпретирует «вероятность 70%» (не как «точно будет»)."
    transfer_test: "Дать 5 утверждений из нового домена (спорт, кулинария) → расставить на шкале 0-1 → объяснить, откуда оценка"
    retrieval_test: "Через неделю: «Что значит "вероятность 30%"? Приведи пример события с такой вероятностью»"

  common_errors:
    - "Путает вероятность 0.5 с «не знаю»: 50% — это конкретная оценка, а не признание невежества"
    - "Не различает частоту и уверенность: «дождь идёт 70 дней из 100» ≠ «я на 70% уверен в дожде завтра» — разные интерпретации вероятности"
    - "Считает, что маленькая вероятность = «не произойдёт»: 1% не равен нулю, а в большой выборке 1%-событие почти наверняка случится"

  domains: [погода (прогнозы), медицина (диагноз), игры/лотереи]

  forms:
    preoperational: "Не рекомендуется на этой глубине (требуется понимание чисел и пропорций)"
    concrete_operational: "«Линейка шансов»: числовая прямая 0-1 на доске → 10 событий на карточках → расставить на прямой, обосновать позицию. 20 мин"
    formal_operational: "«Два прогноза»: один говорит «будет дождь», другой — «вероятность дождя 70%» → обсудить: какой полезнее и почему? 25 мин"
    postformal: "«Аудит уверенности»: выписать 5 своих убеждений → каждому присвоить число 0-1 → обосновать → обсудить с партнёром. 40 мин"

  bridge_template: "Помнишь, как мы сортировали события на «скорее всего / вряд ли»? Теперь научимся описывать эту уверенность ЧИСЛОМ — от 0 до 1."
```

---

## ZP.5 @ Глубина 3 (Apply)

```yaml
cell:
  principle: ZP.5
  principle_name: Вероятность и информация
  depth: 3
  bloom_level: Apply

  can_do:
    - "Могу рассчитать условную вероятность P(A|B) для конкретной задачи (формула Байеса в формате естественных частот)"
    - "Могу объяснить, почему p < 0.05 НЕ означает «гипотеза доказана» — и привести пример ложноположительного результата"
    - "Могу определить: событие имеет мало информации (предсказуемое) или много информации (неожиданное)"
    - "Могу обновить свою оценку вероятности при получении новых данных (байесовское обновление на числовом примере)"

  methods:
    primary: [EDU.M.002, EDU.M.004, EDU.M.005]  # PBL + Experiential + Backwards Design
    meta: [EDU.M.006, EDU.M.007]
    notes: "Ключевой переход: от понимания к расчёту и применению. Формула Байеса — через ЕСТЕСТВЕННЫЕ ЧАСТОТЫ (Gigerenzer), не через абстрактные P(A|B): исследования показывают, что формат натуральных частот помогает даже детям решать байесовские задачи. Обязательно: кризис воспроизводимости как кейс (p-hacking, base rate neglect). Информация по Шеннону: неожиданное событие = много информации. Связь с ZP.1@3: формализация требует аксиоматической базы (аксиомы Колмогорова)."

  prerequisites:
    same_principle: "ZP.5@2"
    cross_principle: ["ZP.1@3"]  # Аксиоматичность для формализации: аксиомы Колмогорова, логическая структура вывода
    cognitive: "Формально-операциональный (11+) или взрослый с базой"

  assessment:
    type: artifact
    criteria: "Решает байесовскую задачу в формате естественных частот (медицинский тест: специфичность + чувствительность → апостериорная вероятность). Объясняет, почему p < 0.05 при базовой ставке 1% даёт >50% ложных срабатываний. Определяет информационное содержание события (больше/меньше)."
    transfer_test: "Задача из незнакомого домена (юриспруденция: надёжность улики, или инженерия: ложная тревога датчика) → байесовский расчёт + интерпретация"
    retrieval_test: "Через неделю: «Тест на болезнь с точностью 99%. Болезнь у 1 из 1000. Тест положительный. Какова вероятность болезни? Объясни за 3 минуты»"

  common_errors:
    - "Base rate neglect: игнорирует базовую частоту, оценивая только «точность» теста — классическая ошибка, лежит в основе кризиса воспроизводимости"
    - "p < 0.05 как «доказательство»: путает «маловероятно при H0» с «H1 верна» — инверсия условной вероятности (P(D|H) ≠ P(H|D))"
    - "Не обновляет оценку при новых данных: «я уже решил» — фиксация на априорной оценке (anchoring bias)"
    - "Переобучение (overfitting): подгоняет модель под конкретные данные вместо извлечения общей закономерности — запоминание без сжатия (N4 из описания ZP.5)"

  domains: [медицина (диагностика), статистика (p-значения), безопасность (ложные тревоги)]

  forms:
    preoperational: "Не применимо"
    concrete_operational: "Не рекомендуется (требуется формальное мышление для работы с дробями и условностями)"
    formal_operational: "«Байесовский доктор»: кейс — тест на редкую болезнь (чувствительность 95%, специфичность 90%, базовая ставка 1%). Решить через таблицу естественных частот (1000 человек → сколько болеют → сколько положительных). 45 мин"
    postformal: "«Аудит решений»: взять 3 своих недавних решения → реконструировать: какова была априорная оценка? Какие данные получены? Как должна была измениться оценка? Изменилась ли? 60 мин"

  bridge_template: "Помнишь, как мы описывали уверенность числом от 0 до 1? Теперь научимся ВЫЧИСЛЯТЬ: как новые данные меняют нашу оценку вероятности."
```

---

## ZP.5 @ Глубина 4 (Analyze)

```yaml
cell:
  principle: ZP.5
  principle_name: Вероятность и информация
  depth: 4
  bloom_level: Analyze

  can_do:
    - "Могу определить, какой тип неопределённости в системе: алеаторная (неустранимая, как бросок кубика) или эпистемическая (устранимая, как незнание о диагнозе)"
    - "Могу объяснить, почему обучение = сжатие: гроккинг как фазовый переход от запоминания к обобщению (Kolmogorov/MDL)"
    - "Могу найти в аргументе/статье нарушение вероятностного мышления (base rate neglect, conjunction fallacy, gambler's fallacy) и объяснить механизм ошибки"
    - "Могу оценить информационную систему по критерию энтропии: сколько неопределённости она снимает, а сколько — нет"
    - "Могу показать, почему conformal prediction ломается при distribution shift — и предложить условия, когда метод работает"

  methods:
    primary: [EDU.M.003, EDU.M.002]  # Case Method + PBL (продвинутый)
    meta: [EDU.M.006, EDU.M.007]
    notes: "Ключевое на этой глубине — не СЧИТАТЬ вероятности, а АНАЛИЗИРОВАТЬ вероятностные рассуждения и информационные потоки. Learning = compression (Power, Steinhardt 2024-2025): grokking — нейросеть сначала запоминает (высокая колмогоровская сложность), потом «сжимает» в обобщение (фазовый переход). Generalized Information Bottleneck (2025): синергетический подход к отбору признаков. IIT 4.0 (2023-2025): интегрированная информация — но критика (Erkenntnis 2025) показывает, что IIT игнорирует внимание. Связь с ZP.2@3: структурный анализ информационных каналов. Связь с ZP.3@2: многомасштабная вероятность (микро vs макро уровни)."

  prerequisites:
    same_principle: "ZP.5@3"
    cross_principle: ["ZP.2@3", "ZP.3@2"]  # Структурность для анализа информационных систем; многомасштабность для анализа вероятности на разных уровнях
    cognitive: "Формально-операциональный (развитый) или постформальный"

  assessment:
    type: artifact + portfolio
    criteria: "Анализ кейса: находит ≥2 вероятностных ошибки в реальном тексте (статья, новость, научная публикация). Классифицирует неопределённость (алеаторная/эпистемическая). Объясняет grokking через MDL. Оценивает информационную ценность источника (снижает энтропию или нет)."
    transfer_test: "Дать научную статью из незнакомого домена (экология, экономика) → найти вероятностные ошибки в аргументации → классифицировать тип неопределённости → оценить информационную ценность выводов"
    retrieval_test: "Через неделю: «Вот два утверждения: (1) "курение вызывает рак" и (2) "этот пациент заболеет раком". Какая неопределённость в каждом? Почему важно их различать?»"

  common_errors:
    - "Путает алеаторную и эпистемическую неопределённость: «Мы не знаем, потому что случайно» — нет, иногда не знаем, потому что недостаточно данных (и МОЖЕМ узнать)"
    - "Считает, что больше данных ВСЕГДА снижает неопределённость: при distribution shift больше данных из старого распределения не помогает (conformal prediction N2)"
    - "Не видит IIT-ловушку: приравнивает «интегрированная информация высокая» к «система сознательна» — IIT 4.0 не учитывает внимание (N1, Erkenntnis 2025)"
    - "Ищет «правильную вероятность» вместо анализа условий: P(X) вне контекста условий C бессмысленно — ZP.5 требует «при условиях C»"

  domains: [научные публикации (кризис воспроизводимости), ИИ/ML (grokking, overfitting), теория информации (энтропия каналов), когнитивная наука (bias)]

  forms:
    preoperational: "Не применимо"
    concrete_operational: "Не применимо"
    formal_operational: "«Детектор вероятностных ошибок»: 3 текста (новость о «прорыве» в медицине, рекламное утверждение «доказано исследованием», заголовок «учёные доказали») → найти: base rate neglect, p-hacking, conjunction fallacy. 60 мин"
    postformal: "«Информационный аудит»: выбрать систему (свой рабочий процесс, канал новостей, ML-пайплайн) → оценить: какую неопределённость снимает каждый элемент? Какая неопределённость алеаторная (не уберёшь), какая эпистемическая (можно снять)? Где grokking, где overfitting? 90 мин"

  bridge_template: "Помнишь, как мы вычисляли вероятности и обновляли оценки при новых данных? Теперь наоборот: будем РАЗБИРАТЬ чужие вероятностные рассуждения — искать ошибки, различать типы неопределённости и оценивать информационную ценность."
```

---

## ZP.5 @ Глубина 5 (Create)

```yaml
cell:
  principle: ZP.5
  principle_name: Вероятность и информация
  depth: 5
  bloom_level: Create

  can_do:
    - "Могу построить вероятностную модель для новой предметной области: определить переменные, условные зависимости, априорные распределения"
    - "Могу спроектировать систему сбора данных, которая максимизирует снижение энтропии (information gain) при минимальных затратах"
    - "Могу формализовать экспертное знание домена в байесовскую сеть (prior elicitation + структура зависимостей)"
    - "Могу обучить другого человека ZP.5 на любой глубине — от «мешка с шарами» до байесовского обновления (peer teaching)"
    - "Могу оценить границы применимости вероятностной модели: где она работает (калиброванные предсказания), где ломается (distribution shift, fat tails)"

  methods:
    primary: [EDU.M.004, EDU.M.008]  # Experiential Learning + Spiral Curriculum
    meta: [EDU.M.006, EDU.M.007]
    notes: "Ключевое — переход от анализа к СОЗДАНИЮ вероятностных моделей. Ученик не только находит ошибки, но строит свои модели и калибрует их. Связь с Shannon-Kolmogorov unification (2024-2026): описание через вероятностное сжатие как способ понимания. Conformal prediction (2024-2025) как инструмент честных предсказаний с гарантиями покрытия. Связь с FPF Trust Calculus: F, G, R как вероятностные оценки надёжности утверждений. Связь с ZP.4@3: оптимизация под неопределённостью (решения при неполной информации)."

  prerequisites:
    same_principle: "ZP.5@4"
    cross_principle: ["ZP.4@3", "FPF.Trust@1"]  # Оптимизация для принятия решений под неопределённостью; Trust Calculus как применение вероятностных оценок к надёжности знания
    cognitive: "Постформальный"

  assessment:
    type: portfolio + peer_teaching
    criteria: "Создана вероятностная модель для домена (≥5 переменных, ≥3 условных зависимости, обоснованные priors). Модель калибрована: предсказания совпадают с реальностью (calibration plot). Проведено обучение другого (peer teaching ZP.5). Определены границы модели: где работает, где нет."
    transfer_test: "Взять совершенно новый домен (не свой) → построить байесовскую сеть за 1 день → собрать данные → проверить калибровку → peer review"
    retrieval_test: "Через месяц: «Какую вероятностную модель ты построил? Где она ошиблась? Что ты из этого узнал?»"

  common_errors:
    - "Чрезмерная точность priors: назначает P = 0.73 без обоснования — ложная точность при реальной неопределённости (spurious precision)"
    - "Не проверяет калибровку: модель «работает» на обучающих данных, но предсказания не совпадают с реальной частотой (overconfidence)"
    - "Игнорирует fat tails: использует нормальное распределение там, где реальные данные имеют тяжёлые хвосты (Taleb: mediocrestan vs extremistan)"
    - "Строит модель в изоляции: не использует Shannon-Kolmogorov для оценки сжатия (модель сложнее данных = переобучение)"

  domains: [собственный профессиональный домен, междисциплинарное моделирование, проектирование систем принятия решений, обучение других]

  forms:
    preoperational: "Не применимо"
    concrete_operational: "Не применимо"
    formal_operational: "Не рекомендуется (нужен постформальный уровень для построения моделей с неопределёнными границами)"
    postformal: "«Архитектор неопределённости»: выбрать домен → определить ключевые переменные → построить байесовскую сеть → назначить priors (обосновать!) → собрать данные → проверить калибровку → итерация. Проект 2-4 недели"

  bridge_template: "Помнишь, как мы анализировали вероятностные ошибки и различали типы неопределённости? Теперь ты сам строишь вероятностные модели — для своей области."
```

---

*CQR self-check: все ячейки >= 10/12*

*Последнее обновление: 2026-02-24*
